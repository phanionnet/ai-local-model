# Local AI Animal Chatbot (Study Notes)

This project is a hands-on learning exercise to understand how to:
- Run an open-source AI model locally
- Expose it via a backend API
- Call it from a simple frontend
- Handle real-world issues like CORS, module paths, and static files

The chatbot takes a single animal name (e.g., Lion, Tiger) and returns
a short descriptive paragraph generated by a local AI model.

---

## 1. System Environment

- OS: Ubuntu 24.04
- RAM: 32 GB
- GPU: NVIDIA (CUDA-enabled)
- Storage: 500 GB SSD
- Python: 3.x
- AI Runtime: Ollama
- Model: phi3:mini (open source)

---

## 2. High-Level Architecture

Frontend (index.html)
   |
   |  HTTP (fetch)
   v
FastAPI Backend (uvicorn)
   |
   |  HTTP
   v
Ollama Local AI Model
   |
   v
Generated Animal Description

Important:
- The AI model runs fully locally.
- No cloud services are used.
- The model is NOT committed to Git.

---

## 3. Repository Structure

ai-local-model/
├── backend/
│   ├── app.py          # FastAPI backend
│   └── __init__.py
├── index.html          # Simple frontend UI
├── README.md           # Study notes
├── animalbot-env/      # Python virtual env (gitignored)
├── .gitignore

---

## 4. Why Ollama Is Used

Ollama simplifies:
- Running LLMs locally
- GPU acceleration
- Model management

Instead of manually loading models with HuggingFace,
Ollama provides a local HTTP API.

This project uses:
- phi3:mini (small, fast, good for short responses)

---

## 5. Backend Setup (FastAPI)

### Create Virtual Environment
```bash
python3 -m venv animalbot-env
source animalbot-env/bin/activate
Install Dependencies
pip install fastapi uvicorn requests

Run Backend
uvicorn backend.app:app --reload


Backend URL:

http://localhost:8000

6. Frontend Usage (Direct File Browsing)

The frontend is opened directly from disk:

file:///.../ai-local-model/index.html


The JavaScript inside the file calls:

http://localhost:8000/describe/{animal}

7. CORS Issue (Important Learning)
Problem

Frontend loaded via file://

Backend served via http://localhost:8000

Browser blocks this due to CORS

Solution

Enable CORS in FastAPI:

from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)


Key Learning:

CORS is enforced by the browser, not the backend

File → HTTP always needs CORS